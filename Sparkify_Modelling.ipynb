{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7a663c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from utility_functions import *\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer,MinMaxScaler, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b21e6074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: string, churned: double, avg_num_of_add_to_playlist_per_session: double, avg_num_of_addfriends_per_session: double, avg_num_of_adverts_per_session: double, avg_num_of_artists_per_session: double, avg_num_of_songs_per_session: double, avg_num_of_thumbs_down_per_session: double, avg_num_of_thumbs_up_per_session: double, avg_num_of_times_settings_changed_per_session: double, average_number_of_visits_to_the_about_page_per_session: double, average_number_of_visits_to_the_help_page_per_session: double, avg_num_of_visits_to_home_per_session: double, avg_num_of_visits_to_the_settings_page_per_session: double, avg_num_of_visits_to_upgrade_page: double, avg_number_of_errors_per_session: double, avg_number_of_visits_to_downgrade_page: double, num_times_user_changed_levels: bigint, num_of_downgrades_submitted: bigint, num_of_upgrades_submitted: bigint, gender: string]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_path = \"train_data.parquet\"\n",
    "test_file_path = \"test_data.parquet\"\n",
    "\n",
    "train_data = import_data_into_dataframe(train_file_path, 'parquet')\n",
    "test_data = import_data_into_dataframe(test_file_path, 'parquet')\n",
    "\n",
    "train_data.persist()\n",
    "test_data.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a11e211d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Train data set for correctness:\n",
      "     type  count\n",
      "0  bigint      3\n",
      "1  double     16\n",
      "2  string      2\n",
      "----------------------------------------\n",
      "Checking Test data set for correctness:\n",
      "     type  count\n",
      "0  bigint      3\n",
      "1  double     16\n",
      "2  string      2\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking Train data set for correctness:\")\n",
    "print(count_column_types(train_data).iloc[:, :2])\n",
    "print('-'*40)\n",
    "print(\"Checking Test data set for correctness:\")\n",
    "print(count_column_types(test_data).iloc[:, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3cb205d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['num_times_user_changed_levels',\n",
       " 'num_of_downgrades_submitted',\n",
       " 'num_of_upgrades_submitted',\n",
       " 'avg_num_of_add_to_playlist_per_session',\n",
       " 'avg_num_of_addfriends_per_session',\n",
       " 'avg_num_of_adverts_per_session',\n",
       " 'avg_num_of_artists_per_session',\n",
       " 'avg_num_of_songs_per_session',\n",
       " 'avg_num_of_thumbs_down_per_session',\n",
       " 'avg_num_of_thumbs_up_per_session',\n",
       " 'avg_num_of_times_settings_changed_per_session',\n",
       " 'average_number_of_visits_to_the_about_page_per_session',\n",
       " 'average_number_of_visits_to_the_help_page_per_session',\n",
       " 'avg_num_of_visits_to_home_per_session',\n",
       " 'avg_num_of_visits_to_the_settings_page_per_session',\n",
       " 'avg_num_of_visits_to_upgrade_page',\n",
       " 'avg_number_of_errors_per_session',\n",
       " 'avg_number_of_visits_to_downgrade_page']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list of numeric column names, have to remove the churned column itself\n",
    "numeric_column_names = get_columns_of_type(train_data, \"bigint\")\n",
    "numeric_column_names.extend(get_columns_of_type(train_data, \"double\"))\n",
    "numeric_column_names.remove('churned') #remove churned column\n",
    "numeric_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f72db1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of categoric column names and remove userId from it \n",
    "categoric_column_names = get_columns_of_type(train_data, \"string\")\n",
    "categoric_column_names.remove('userId')\n",
    "categoric_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bb5be74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipeline_stages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c680496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling numeric columns\n",
    "numeric_vec_assembler = VectorAssembler(inputCols=numeric_column_names, outputCol=\"numeric_features\") # create a vector of all the numeric columns\n",
    "pipeline_stages.append(numeric_vec_assembler)\n",
    "\n",
    "minmax_scaler = MinMaxScaler(inputCol=\"numeric_features\", outputCol=\"numeric_features_scaled\") # minmax scale all numeric columns\n",
    "pipeline_stages.append(minmax_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f98e3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding the categorical column as gender is binary in this case\n",
    "str_indexer = StringIndexer(inputCols=categoric_column_names, outputCols=[name+'_indexed' for name in categoric_column_names], handleInvalid='skip') # encode all categorical features\n",
    "pipeline_stages.append(str_indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e993aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a vector of all the features\n",
    "feature_columns = [\"numeric_features_scaled\", \"gender_indexed\"]\n",
    "feature_assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\") # create the combined features vector\n",
    "pipeline_stages.append(feature_assembler)\n",
    "\n",
    "output_label_indexer = StringIndexer(inputCol='churned', outputCol='label') # encode the churned column\n",
    "pipeline_stages.append(output_label_indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21afc97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|churned|features                                                                                                                                                                                                                                                                                                   |label|\n",
      "+-------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|1.0    |[0.0,0.0,0.0,0.25,0.3213793103448276,0.676923076923077,0.16524590163934424,0.14317548746518105,0.125,0.29411764705882354,0.0,0.0,0.4175,0.22666666666666666,0.0,0.14285714285714285,0.4,0.0,1.0]                                                                                                           |1.0  |\n",
      "|0.0    |[0.16666666666666666,0.0,0.3333333333333333,0.25,0.5062068965517241,0.19230769230769232,0.28662295081967215,0.2864345403899721,0.23125,0.3205882352941177,0.3333333333333333,0.46799999999999997,0.3225,0.28200000000000003,0.2783333333333333,0.14285714285714285,0.4,0.44,1.0]                           |0.0  |\n",
      "|0.0    |[0.16666666666666666,0.0,0.3333333333333333,0.31785714285714284,0.43310344827586206,0.2561538461538462,0.27672131147540985,0.266100278551532,0.25,0.5176470588235295,0.3333333333333333,0.4,0.25,0.314,0.3333333333333333,0.2857142857142857,0.4,0.7272727272727273,0.0]                                   |0.0  |\n",
      "|1.0    |[0.3333333333333333,0.3333333333333333,0.3333333333333333,0.3364285714285714,0.4482758620689655,0.22153846153846155,0.379344262295082,0.3604178272980501,0.35375,0.5623529411764706,0.3333333333333333,0.48,0.5,0.3333333333333333,0.30833333333333335,0.14285714285714285,0.5,0.5290909090909092,1.0]     |1.0  |\n",
      "|0.0    |[0.3333333333333333,0.3333333333333333,0.3333333333333333,0.19357142857142856,0.2524137931034483,0.21153846153846156,0.12829508196721312,0.11233983286908078,0.1875,0.18941176470588236,0.3333333333333333,0.4,0.25,0.14666666666666667,0.1883333333333333,0.14285714285714285,0.4,0.30363636363636365,0.0]|0.0  |\n",
      "+-------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: string, churned: double, avg_num_of_add_to_playlist_per_session: double, avg_num_of_addfriends_per_session: double, avg_num_of_adverts_per_session: double, avg_num_of_artists_per_session: double, avg_num_of_songs_per_session: double, avg_num_of_thumbs_down_per_session: double, avg_num_of_thumbs_up_per_session: double, avg_num_of_times_settings_changed_per_session: double, average_number_of_visits_to_the_about_page_per_session: double, average_number_of_visits_to_the_help_page_per_session: double, avg_num_of_visits_to_home_per_session: double, avg_num_of_visits_to_the_settings_page_per_session: double, avg_num_of_visits_to_upgrade_page: double, avg_number_of_errors_per_session: double, avg_number_of_visits_to_downgrade_page: double, num_times_user_changed_levels: bigint, num_of_downgrades_submitted: bigint, num_of_upgrades_submitted: bigint, gender: string, numeric_features: vector, numeric_features_scaled: vector, gender_indexed: double, features: vector, label: double]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tranforming the train data set using the pipeline\n",
    "data_pipeline = Pipeline(stages=pipeline_stages)\n",
    "data_pipeline_model = data_pipeline.fit(train_data)\n",
    "transformed_data = temp_model.transform(train_data)\n",
    "transformed_data.select(\"churned\", \"features\", \"label\").show(5, truncate=False)\n",
    "transformed_data.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a79f047",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cae29f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate different algorithms\n",
    "model_names = ['logistic regression', 'random forest', 'gradient-boosted tree', 'linear svc',\n",
    "               'decision tree', 'naive bayes']\n",
    "estimators = []\n",
    "\n",
    "lr = LogisticRegression()\n",
    "estimators.append(lr)\n",
    "rf = RandomForestClassifier(seed = 42)\n",
    "estimators.append(rf)\n",
    "gbt = GBTClassifier(seed = 42)\n",
    "estimators.append(gbt)\n",
    "svc = LinearSVC()\n",
    "estimators.append(svc)\n",
    "dt = DecisionTreeClassifier(seed = 42)\n",
    "estimators.append(dt)\n",
    "nb = NaiveBayes()\n",
    "estimators.append(nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5946ccfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: logistic regression\n",
      "Cross validation score: 0.6065959019718983\n",
      "AUCROC: 0.7153784219001608\n",
      "\n",
      "Algorithm: random forest\n",
      "Cross validation score: 0.5990755120479732\n",
      "AUCROC: 0.9315172660583285\n",
      "\n",
      "Algorithm: gradient-boosted tree\n",
      "Cross validation score: 0.5207247125103985\n",
      "AUCROC: 0.9997316156736447\n",
      "\n",
      "Algorithm: linear svc\n",
      "Cross validation score: 0.6033980599829254\n",
      "AUCROC: 0.6823224190373949\n",
      "\n",
      "Algorithm: decision tree\n",
      "Cross validation score: 0.5244351974131821\n",
      "AUCROC: 0.40915190552871716\n",
      "\n",
      "Algorithm: naive bayes\n",
      "Cross validation score: 0.500353935878279\n",
      "AUCROC: 0.5078278761853641\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_metric_value = -99\n",
    "best_model = None\n",
    "\n",
    "for model_name, est in zip(model_names,estimators):\n",
    "    \n",
    "    evaluator = BinaryClassificationEvaluator() # using a binary classification evalution with metric as AUCROC\n",
    "    \n",
    "    grid = ParamGridBuilder().build() # using an empty grid\n",
    "    \n",
    "    crossval = CrossValidator(estimator = est,\n",
    "                            estimatorParamMaps=grid,\n",
    "                            evaluator = evaluator) # using the default value for number of folds: 3\n",
    "    \n",
    "    cvmodel = crossval.fit(transformed_data)\n",
    "    \n",
    "    metric_val = evaluator.evaluate(cvmodel.transform(transformed_data))\n",
    "    \n",
    "    print(f\"Algorithm: {model_name}\")\n",
    "    print(f\"Cross validation score: {cvmodel.avgMetrics[0]}\")\n",
    "    print(f\"AUCROC: {metric_val}\")\n",
    "    print()\n",
    "    \n",
    "    if metric_val > best_metric_value:\n",
    "        best_metric_value = metric_val\n",
    "        best_model = cvmodel.bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aca1a7b",
   "metadata": {},
   "source": [
    "As it can be seen, logistic regression had the best average cross validation score. Followed by Linear SVC.\n",
    "We will tune hyperparameters for the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "604e180d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(estimator, evaluator, paramGrid, data):\n",
    "    crossval = CrossValidator(estimator = est,\n",
    "                            estimatorParamMaps=grid,\n",
    "                            evaluator = evaluator) # using the default value for number of folds: 3\n",
    "    \n",
    "    cvmodel = crossval.fit(data)\n",
    "    \n",
    "    return cvmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31facbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "est = LogisticRegression()\n",
    "\n",
    "grid = ParamGridBuilder().addGrid(est.maxIter, [100, 200, 300]).addGrid(est.regParam, [0.001, 0.01, 0.1, 1, 3, 5]).addGrid(est.threshold, [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]).build()\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "lr = train_classifier(est, evaluator, grid, transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9967cdfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.6184790292341781\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cross validation score: {lr.avgMetrics[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e90c55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(lr.bestModel.getElasticNetParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c3b7eaa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"aggregationDepth: suggested depth for treeAggregate (>= 2). (default: 2)\\nelasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0)\\nfamily: The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial (default: auto)\\nfeaturesCol: features column name. (default: features)\\nfitIntercept: whether to fit an intercept term. (default: True)\\nlabelCol: label column name. (default: label)\\nlowerBoundsOnCoefficients: The lower bounds on coefficients if fitting under bound constrained optimization. The bound matrix must be compatible with the shape (1, number of features) for binomial regression, or (number of classes, number of features) for multinomial regression. (undefined)\\nlowerBoundsOnIntercepts: The lower bounds on intercepts if fitting under bound constrained optimization. The bounds vector size must beequal with 1 for binomial regression, or the number oflasses for multinomial regression. (undefined)\\nmaxBlockSizeInMB: maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be >= 0. (default: 0.0)\\nmaxIter: max number of iterations (>= 0). (default: 100, current: 100)\\npredictionCol: prediction column name. (default: prediction)\\nprobabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities. (default: probability)\\nrawPredictionCol: raw prediction (a.k.a. confidence) column name. (default: rawPrediction)\\nregParam: regularization parameter (>= 0). (default: 0.0, current: 0.01)\\nstandardization: whether to standardize the training features before fitting the model. (default: True)\\nthreshold: Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p]. (default: 0.5, current: 0.3)\\nthresholds: Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values > 0, excepting that at most one value may be 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class's threshold. (undefined)\\ntol: the convergence tolerance for iterative algorithms (>= 0). (default: 1e-06)\\nupperBoundsOnCoefficients: The upper bounds on coefficients if fitting under bound constrained optimization. The bound matrix must be compatible with the shape (1, number of features) for binomial regression, or (number of classes, number of features) for multinomial regression. (undefined)\\nupperBoundsOnIntercepts: The upper bounds on intercepts if fitting under bound constrained optimization. The bound vector size must be equal with 1 for binomial regression, or the number of classes for multinomial regression. (undefined)\\nweightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.bestModel.explainParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5023375c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxIter:  100\n",
      "threshold:  0.3\n",
      "regParam:  0.01\n"
     ]
    }
   ],
   "source": [
    "print(\"maxIter: \",lr.bestModel.getMaxIter())\n",
    "print(\"threshold: \", lr.bestModel.getThreshold())\n",
    "print(\"regParam: \", lr.bestModel.getRegParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62c00d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.24864945, -0.10793773, -0.25570171,  1.03269487, -0.49079552,\n",
       "        2.30837552,  0.46266292,  0.79770161,  1.70916452, -1.33829473,\n",
       "       -1.29602326, -0.72130076,  0.92615866, -0.20009427,  0.05294991,\n",
       "       -0.04719589, -1.50679953,  1.85935604,  0.29654608])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.bestModel.coefficients.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0106f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = numeric_column_names + categoric_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7794890e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>LR coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_times_user_changed_levels</td>\n",
       "      <td>-0.248649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>num_of_downgrades_submitted</td>\n",
       "      <td>-0.107938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num_of_upgrades_submitted</td>\n",
       "      <td>-0.255702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg_num_of_add_to_playlist_per_session</td>\n",
       "      <td>1.032695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg_num_of_addfriends_per_session</td>\n",
       "      <td>-0.490796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>avg_num_of_adverts_per_session</td>\n",
       "      <td>2.308376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>avg_num_of_artists_per_session</td>\n",
       "      <td>0.462663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>avg_num_of_songs_per_session</td>\n",
       "      <td>0.797702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>avg_num_of_thumbs_down_per_session</td>\n",
       "      <td>1.709165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>avg_num_of_thumbs_up_per_session</td>\n",
       "      <td>-1.338295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>avg_num_of_times_settings_changed_per_session</td>\n",
       "      <td>-1.296023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>average_number_of_visits_to_the_about_page_per_session</td>\n",
       "      <td>-0.721301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>average_number_of_visits_to_the_help_page_per_session</td>\n",
       "      <td>0.926159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>avg_num_of_visits_to_home_per_session</td>\n",
       "      <td>-0.200094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>avg_num_of_visits_to_the_settings_page_per_session</td>\n",
       "      <td>0.052950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>avg_num_of_visits_to_upgrade_page</td>\n",
       "      <td>-0.047196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>avg_number_of_errors_per_session</td>\n",
       "      <td>-1.506800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>avg_number_of_visits_to_downgrade_page</td>\n",
       "      <td>1.859356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gender</td>\n",
       "      <td>0.296546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   feature  LR coefficient\n",
       "0                            num_times_user_changed_levels       -0.248649\n",
       "1                              num_of_downgrades_submitted       -0.107938\n",
       "2                                num_of_upgrades_submitted       -0.255702\n",
       "3                   avg_num_of_add_to_playlist_per_session        1.032695\n",
       "4                        avg_num_of_addfriends_per_session       -0.490796\n",
       "5                           avg_num_of_adverts_per_session        2.308376\n",
       "6                           avg_num_of_artists_per_session        0.462663\n",
       "7                             avg_num_of_songs_per_session        0.797702\n",
       "8                       avg_num_of_thumbs_down_per_session        1.709165\n",
       "9                         avg_num_of_thumbs_up_per_session       -1.338295\n",
       "10           avg_num_of_times_settings_changed_per_session       -1.296023\n",
       "11  average_number_of_visits_to_the_about_page_per_session       -0.721301\n",
       "12   average_number_of_visits_to_the_help_page_per_session        0.926159\n",
       "13                   avg_num_of_visits_to_home_per_session       -0.200094\n",
       "14      avg_num_of_visits_to_the_settings_page_per_session        0.052950\n",
       "15                       avg_num_of_visits_to_upgrade_page       -0.047196\n",
       "16                        avg_number_of_errors_per_session       -1.506800\n",
       "17                  avg_number_of_visits_to_downgrade_page        1.859356\n",
       "18                                                  gender        0.296546"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_coefficient = pd.DataFrame.from_dict({'feature':all_features,'LR coefficient': lr.bestModel.coefficients.values})\n",
    "feature_coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d5aec2",
   "metadata": {},
   "source": [
    "Add the logistic regression model as the final stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4c12d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_stages.append(LogisticRegression(maxIter=100, regParam=0.01, threshold=0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a38b56",
   "metadata": {},
   "source": [
    "Transform and evaluate performance on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e1221b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC score on test data:  0.5144596651445966\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "training_pipeline = Pipeline(stages=pipeline_stages)\n",
    "training_pipeline_model = training_pipeline.fit(train_data)\n",
    "\n",
    "transformed_test_data = training_pipeline_model.transform(test_data)\n",
    "\n",
    "print(\"AUCROC score on test data: \", evaluator.evaluate(transformed_test_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
